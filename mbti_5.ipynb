{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alone-timeline",
   "metadata": {},
   "source": [
    "# 자연어 처리를 통한 성격 예측 : 테스트 및 실제 데이터 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romance-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')               # Turn the warnings off.\n",
    "from xgboost import XGBClassifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-yield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-program",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBC = joblib.load('XGBC.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "standing-baseline",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-6e76880339eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "pleasant-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_predict(posts):\n",
    "\n",
    "    corpus = []\n",
    "    \n",
    "    post = re.sub(r'(https|http)?:?\\/?\\/?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', ' ', posts)  # url 제거\n",
    "    post = post.lower()           # 소문자화\n",
    "    post = re.sub(r'\\W', ' ', post)\n",
    "    post = re.sub(r'_', ' ', post)\n",
    "    post = re.sub(r'\\d+', ' ', post)\n",
    "    post = re.sub(r'\\s+', ' ', post)\n",
    "    post = re.sub(r'^\\s|\\s$', '', post)\n",
    "    \n",
    "\n",
    "    words = nltk.word_tokenize(post)                                # 단어 단위로 토큰화.\n",
    "    words = [x for x in words if x not in stopwords]      # 불용어 제거.\n",
    "    words = [x for x in words if len(x) > 2]              # 특정 길이 이하의 의미없는 문자 제거\n",
    "    post = ' '.join(words)            # 다시 문장으로 합치기\n",
    "    \n",
    "    corpus.append(post)\n",
    "    \n",
    "    X_real = vectorizer.transform(corpus).toarray()\n",
    "    \n",
    "    return XGBC.predict_proba(X_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-celebrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "serious-liquid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89424586, 0.10575411]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_predict(\"Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight! Donald Trump will be appearing on The View tomorrow morning to discuss Celebrity Apprentice and his new book Think Like A Champion! Donald Trump reads Top Ten Financial Tips on Late Show with David Letterman: http://tinyurl.ㅁㄴㅇㄹst: Celebrity Apprentㅁㄴㅇㄹㅁㄴㅇㄹ5e abuild walls than cling to them\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "signal-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = pd.read_csv(\"realdonaldtrump.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "conceptual-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = trump.content[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "romantic-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = \" \".join([x for x in trump])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "exposed-arthritis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87692523, 0.12307476]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_predict(trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-london",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-tragedy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 실제 트윗 예측\n",
    "\n",
    "stopwords = stopwords.words(\"english\")\n",
    "\n",
    "def personal_predict(posts):\n",
    "\n",
    "    corpus = []\n",
    "    \n",
    "    post = re.sub(r'(https|http)?:?\\/?\\/?(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)', ' ', posts)  # url 제거\n",
    "    post = post.lower()           # 소문자화\n",
    "    post = re.sub(r'\\W', ' ', post)\n",
    "    post = re.sub(r'_', ' ', post)\n",
    "    post = re.sub(r'\\d+', ' ', post)\n",
    "    post = re.sub(r'\\s+', ' ', post)\n",
    "    post = re.sub(r'^\\s|\\s$', '', post)\n",
    "    \n",
    "\n",
    "    words = nltk.word_tokenize(post)                                # 단어 단위로 토큰화.\n",
    "    words = [x for x in words if x not in stopwords]      # 불용어 제거.\n",
    "    words = [x for x in words if len(x) > 2]              # 특정 길이 이하의 의미없는 문자 제거\n",
    "    post = ' '.join(words)            # 다시 문장으로 합치기\n",
    "    \n",
    "    corpus.append(post)\n",
    "    \n",
    "    X_real = vectorizer.transform(corpus).toarray()\n",
    "    \n",
    "    return XGBC.predict_proba(X_real)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "personal_predict(\"Be sure to tune in and watch Donald Trump on Late Night with David Letterman as he presents the Top Ten List tonight! Donald Trump will be appearing on The View tomorrow morning to discuss Celebrity Apprentice and his new book Think Like A Champion! Donald Trump reads Top Ten Financial Tips on Late Show with David Letterman: http://tinyurl.ㅁㄴㅇㄹst: Celebrity Apprentㅁㄴㅇㄹㅁㄴㅇㄹ5e abuild walls than cling to them\")\n",
    "\n",
    "trump = pd.read_csv(\"realdonaldtrump.csv\")\n",
    "\n",
    "trump = trump.content[100]\n",
    "\n",
    "trump = \" \".join([x for x in trump])\n",
    "\n",
    "personal_predict(trump)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
